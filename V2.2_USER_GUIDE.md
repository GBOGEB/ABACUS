# V2.2 USER GUIDE - 12-CLUSTER Orchestrator System
**Version:** 2.2.0  
**Date:** 2025-11-11  
**Status:** Production Ready âœ…

---

## ğŸ“– TABLE OF CONTENTS

1. [Quick Start](#quick-start)
2. [System Overview](#system-overview)
3. [Installation & Setup](#installation--setup)
4. [Running Pipelines](#running-pipelines)
5. [Agent Management](#agent-management)
6. [Configuration](#configuration)
7. [Monitoring & Debugging](#monitoring--debugging)
8. [Troubleshooting](#troubleshooting)
9. [Best Practices](#best-practices)
10. [Advanced Usage](#advanced-usage)
11. [Reference](#reference)

---

## ğŸš€ QUICK START

### 1. Run Your First Test (30 seconds)
```bash
# Navigate to project directory
cd C:\Users\gbonthuy\OneDrive - Studiecentrum voor Kernenergie\Master_Input

# Run quick smoke test
python orchestrator.py --run quick_test --config orchestrator_config.yaml

# Expected: Exit code 0, execution time ~1.7s
```

### 2. View Results
```bash
# Check output
dir pipeline_results\

# You should see: quick_test_<timestamp>.json
```

### 3. Run Multi-Stage Pipeline
```bash
# Run test pipeline (2 stages)
python orchestrator.py --run test_pipeline --config orchestrator_config.yaml

# Expected: Exit code 0, execution time ~3.6s
```

**âœ… If all three steps complete successfully, your system is operational!**

---

## ğŸ—ï¸ SYSTEM OVERVIEW

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          ORCHESTRATOR (orchestrator.py)          â”‚
â”‚  - Pipeline Management                           â”‚
â”‚  - Agent Scheduling                              â”‚
â”‚  - Result Aggregation                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     KEB      â”‚  â”‚    GBOGEB     â”‚
â”‚  Execution   â”‚  â”‚ Observability â”‚
â”‚  Backbone    â”‚  â”‚  & Metrics    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     EXECUTION TRACKER      â”‚
    â”‚  - Phase Management        â”‚
    â”‚  - Logging & Audit         â”‚
    â”‚  - Metrics Collection      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    12 AGENTS (6+6)         â”‚
    â”‚  - 6 OPTIMIZED Stubs       â”‚
    â”‚  - 6 Canonical Agents      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

| Component | Purpose | Status |
|-----------|---------|--------|
| **Orchestrator** | Coordinates all agent execution | âœ… Operational |
| **KEB** | Task scheduling and execution | âœ… Tested (32.6s) |
| **GBOGEB** | Metrics and observability | âš ï¸ Optional |
| **Execution Tracker** | Logging and audit trails | âœ… Operational |
| **MCP Controller** | External control interface | âœ… Functional |
| **12 Agents** | Processing workload | âœ… All operational |

---

## ğŸ’¾ INSTALLATION & SETUP

### Prerequisites
```bash
# Check Python version (requires 3.8+)
python --version

# Should output: Python 3.8.x or higher
```

### Option 1: PowerShell Setup (Windows)
```powershell
# Run automated setup
.\setup_environment_v2.2.ps1

# This will:
# - Validate Python installation
# - Create virtual environment (optional)
# - Install dependencies
# - Test components
# - Generate readiness report
```

### Option 2: Bash Setup (Linux/Mac)
```bash
# Make executable
chmod +x setup_environment_v2.2.sh

# Run setup
./setup_environment_v2.2.sh

# Same features as PowerShell version
```

### Option 3: Manual Setup
```bash
# 1. Install optional dependencies
pip install pyyaml psutil debugpy

# 2. Test core components
python keb.py --test
python execution_tracker.py --test

# 3. Validate configuration
python orchestrator.py --validate-config

# 4. Run first test
python orchestrator.py --run quick_test --config orchestrator_config.yaml
```

### Verification
```bash
# Check all systems
python orchestrator.py --health-check

# Expected output:
# âœ… Orchestrator: Operational
# âœ… KEB: Operational
# âœ… Execution Tracker: Operational
# âœ… Agents: 12 found
# âœ… Pipelines: 3 configured
```

---

## ğŸ¯ RUNNING PIPELINES

### Available Pipelines

#### 1. quick_test (Fastest - 1.7s)
**Purpose:** Quick smoke test for validation  
**Stages:** 1 (smoke_test)  
**Agents:** 1 (smoke_tester)  
**Use Case:** CI/CD checks, rapid validation

```bash
python orchestrator.py --run quick_test --config orchestrator_config.yaml
```

#### 2. test_pipeline (Standard - 3.6s)
**Purpose:** Multi-stage testing  
**Stages:** 2 (validation, analysis)  
**Agents:** 2 (quick_smoke x2)  
**Use Case:** Integration testing, pre-deployment checks

```bash
python orchestrator.py --run test_pipeline --config orchestrator_config.yaml
```

#### 3. run_pipeline (Full - 400s+)
**Purpose:** Complete workflow with all agents  
**Stages:** 4 (validation, analysis, processing, documentation)  
**Agents:** 6 (all agents)  
**Use Case:** Production runs, comprehensive processing

```bash
python orchestrator.py --run run_pipeline --config orchestrator_config.yaml
```

### Common Options

```bash
# Run with debug output
python orchestrator.py --run quick_test --config orchestrator_config.yaml --verbose

# Run with remote debugging (port 5678)
python orchestrator.py --run quick_test --debug

# Dry run (validate without executing)
python orchestrator.py --run quick_test --dry-run

# Override timeout
python orchestrator.py --run quick_test --timeout 120

# Save results to custom location
python orchestrator.py --run quick_test --output-dir my_results/
```

### Reading Results

**Result files are JSON format:**
```json
{
  "pipeline": "quick_test",
  "timestamp": "2025-11-11T09:38:35.081902",
  "execution_time": 1.6456034183502197,
  "stages": [
    {
      "stage": "smoke_test",
      "results": [
        {
          "agent": "smoke_tester",
          "success": true,
          "execution_time": 1.643s,
          "return_code": 0
        }
      ]
    }
  ],
  "success": true
}
```

**Key fields:**
- `success`: Overall pipeline status (true/false)
- `execution_time`: Total time in seconds
- `return_code`: 0 = success, non-zero = error
- `timestamp`: ISO 8601 format

---

## ğŸ¤– AGENT MANAGEMENT

### List All Agents
```bash
# Via orchestrator
python orchestrator.py --list-agents

# Via MCP controller
python mcp_controller.py --list-agents

# Expected output: 12 agents
```

### Agent Types

#### OPTIMIZED Stubs (Fast, for testing)
```
Name                                    | Size  | Speed | Purpose
----------------------------------------|-------|-------|------------------
analysis_smoke_test_OPTIMIZED.py        | 1.9KB | 1.6s  | Quick validation
analysis_cryo_dm_v2.1_OPTIMIZED.py      | 2.0KB | 1.7s  | Cryo optimization
analysis_document_consumer_OPTIMIZED.py | 2.0KB | 1.8s  | Document processing
analysis_artifact_analyzer_OPTIMIZED.py | 2.0KB | 1.7s  | Artifact analysis
recursive_framework_v2.1_OPTIMIZED.py   | 2.7KB | 2.0s  | Recursive tasks
documentation_framework_v2.0_OPTIMIZED.py| 2.1KB | 1.9s  | Documentation gen
```

#### Canonical Agents (Full features, production)
```
Name                                            | Size | Speed  | Purpose
------------------------------------------------|------|--------|------------------
cryo_analysis_v3_DMAIC_ULTRA_OPTIMIZED.py       | 35KB | 30-45s | DMAIC cryo analysis
CANONICAL_DOCUMENT_CONSUMER_v6.1.0_OPTIMIZED.py | 28KB | 20-30s | Document processing
smoke_test_runner_ULTRA_OPTIMIZED.py            | 8.5KB| 7-10s  | Comprehensive tests
comprehensive_artifact_analyzer_OPTIMIZED.py    | 13KB | 10-15s | Deep artifact scan
COMPREHENSIVE_RECURSIVE_CRYO_PROCESS_*          | 53KB | 40-60s | Recursive framework
CRYO_LINAC_COMPREHENSIVE_DOCUMENTATION_*        | 27KB | 25-35s | Documentation sys
```

### Test Individual Agent
```bash
# Run directly
python local_mcp/agents/analysis_smoke_test_OPTIMIZED.py

# With debugging
python -m debugpy --listen 5678 local_mcp/agents/analysis_smoke_test_OPTIMIZED.py

# Expected: Exit code 0
```

### Agent Configuration
Agents are configured in `orchestrator_config.yaml`:

```yaml
agents:
  smoke_tester:
    path: "local_mcp/agents/analysis_smoke_test_OPTIMIZED.py"
    timeout: 30      # seconds
    priority: 10     # higher = earlier execution
    enabled: true
```

---

## âš™ï¸ CONFIGURATION

### Main Config File: orchestrator_config.yaml

#### Structure
```yaml
# Agent Definitions
agents:
  <agent_name>:
    path: <path_to_agent.py>
    timeout: <seconds>
    priority: <1-10>
    enabled: <true/false>

# Pipeline Definitions
pipelines:
  <pipeline_name>:
    stages:
      - stage: <stage_name>
        agents: [<agent_name>, ...]
        parallel: <true/false>

# Global Settings
debug:
  enabled: <true/false>
  port: <port_number>

logging:
  level: <DEBUG/INFO/WARNING/ERROR>
  file: <log_file_path>
```

### Example: Add New Agent

1. **Create agent file** in `local_mcp/agents/my_agent.py`

2. **Add to config:**
```yaml
agents:
  my_custom_agent:
    path: "local_mcp/agents/my_agent.py"
    timeout: 45
    priority: 5
    enabled: true
```

3. **Add to pipeline:**
```yaml
pipelines:
  custom_pipeline:
    stages:
      - stage: custom_stage
        agents: [my_custom_agent]
        parallel: false
```

4. **Test:**
```bash
python orchestrator.py --run custom_pipeline --config orchestrator_config.yaml
```

### Example: Modify Timeouts

```yaml
# Increase timeout for slow agent
agents:
  cryo_optimizer:
    timeout: 120  # was 60, now 120 seconds
```

---

## ğŸ” MONITORING & DEBUGGING

### Real-Time Monitoring

#### Terminal Output
```bash
# Run with verbose output
python orchestrator.py --run test_pipeline --verbose

# Output shows:
# [2025-11-11 10:30:00] Stage: validation
# [2025-11-11 10:30:01] Agent: quick_smoke - RUNNING
# [2025-11-11 10:30:03] Agent: quick_smoke - SUCCESS (1.6s)
# [2025-11-11 10:30:03] Stage: validation - COMPLETE
```

#### Execution Tracker
```bash
# View current phase
cat execution_tracking/phases/current_phase.json

# View execution logs
ls execution_tracking/executions/

# View metrics
cat execution_tracking/metrics/summary.json
```

### Remote Debugging (Port 5678)

#### Start with Debugger
```bash
python orchestrator.py --run test_pipeline --debug
```

#### Attach from VS Code
Add to `.vscode/launch.json`:
```json
{
  "name": "Attach to Orchestrator",
  "type": "python",
  "request": "attach",
  "connect": {
    "host": "localhost",
    "port": 5678
  }
}
```

#### Attach from PyCharm
1. Run â†’ Edit Configurations
2. Add â†’ Python Remote Debug
3. Host: localhost, Port: 5678
4. Click "Debug"

### Log Analysis
```bash
# Analyze all executions
python analyze_executions.py

# Output shows:
# Total Executions: 3
# Success Rate: 100%
# Average Time: 2.3s
# Errors: 0
```

---

## ğŸ”§ TROUBLESHOOTING

### Common Issues

#### 1. "Agent not found" Error
**Symptom:** `FileNotFoundError: local_mcp/agents/xxx.py`

**Solution:**
```bash
# List available agents
python orchestrator.py --list-agents

# Verify path in config matches actual file
ls local_mcp/agents/

# Fix path in orchestrator_config.yaml
```

#### 2. Timeout Errors
**Symptom:** `Agent 'xxx' exceeded timeout of 30s`

**Solution:**
```bash
# Option A: Increase timeout in config
# Edit orchestrator_config.yaml:
agents:
  xxx:
    timeout: 60  # increase from 30

# Option B: Override via command line
python orchestrator.py --run pipeline --timeout 120
```

#### 3. Port 5678 Already in Use
**Symptom:** `Address already in use`

**Solution:**
```bash
# Find process using port
netstat -ano | findstr :5678

# Kill process (Windows)
taskkill /PID <pid> /F

# Or change port in config
debug:
  port: 5679
```

#### 4. Import Errors
**Symptom:** `ModuleNotFoundError: No module named 'yaml'`

**Solution:**
```bash
# Install missing dependencies
pip install pyyaml psutil debugpy

# Or run setup script
.\setup_environment_v2.2.ps1
```

#### 5. Pipeline Fails Silently
**Symptom:** No error message, but results missing

**Solution:**
```bash
# Enable verbose logging
python orchestrator.py --run pipeline --verbose --log-level DEBUG

# Check execution logs
cat execution_tracking/executions/latest.log

# Analyze with tool
python analyze_executions.py
```

### GBOGEB Timeout (Known Issue)
**Symptom:** GBOGEB test hangs for 120+ seconds

**Status:** Non-critical, observability layer

**Workaround:**
```bash
# Skip GBOGEB test
python orchestrator.py --run pipeline --skip-gbogeb

# Or increase timeout
python gbogeb.py --test --timeout 180
```

### Getting Help

#### Check Health
```bash
python orchestrator.py --health-check
```

#### Validate Config
```bash
python orchestrator.py --validate-config
```

#### Run Diagnostics
```bash
# Test all components
python keb.py --test
python execution_tracker.py --test
python analyze_executions.py --test
```

---

## ğŸ’¡ BEST PRACTICES

### 1. Development Workflow
```bash
# 1. Quick test after changes
python orchestrator.py --run quick_test

# 2. Integration test
python orchestrator.py --run test_pipeline

# 3. Full test (before commit)
python orchestrator.py --run run_pipeline

# 4. Analyze results
python analyze_executions.py
```

### 2. Use OPTIMIZED Stubs for Testing
- Faster feedback (1-2s vs 30-60s)
- Same interface as canonical agents
- Perfect for CI/CD

### 3. Monitor Execution Tracking
```bash
# Check after each run
ls execution_tracking/executions/

# Review metrics
cat execution_tracking/metrics/summary.json
```

### 4. Version Control
- Keep `orchestrator_config.yaml` in git
- Track pipeline results for regression analysis
- Document custom agents

### 5. Performance Optimization
```bash
# Run stages in parallel when possible
pipelines:
  my_pipeline:
    stages:
      - stage: parallel_stage
        agents: [agent1, agent2, agent3]
        parallel: true  # run simultaneously
```

### 6. Error Handling
- Always check return codes
- Enable verbose logging during development
- Use try-run before production deployment

```bash
# Dry run first
python orchestrator.py --run pipeline --dry-run

# Then execute
python orchestrator.py --run pipeline
```

---

## ğŸš€ ADVANCED USAGE

### Custom Pipeline Creation

**1. Define in YAML:**
```yaml
pipelines:
  my_advanced_pipeline:
    stages:
      - stage: validation
        agents: [smoke_tester]
        parallel: false
        
      - stage: processing
        agents: [cryo_optimizer, document_consumer, artifact_analyzer]
        parallel: true  # run in parallel
        
      - stage: finalization
        agents: [documentation_framework]
        parallel: false
```

**2. Run:**
```bash
python orchestrator.py --run my_advanced_pipeline --config orchestrator_config.yaml
```

### Batch Execution

**Windows:**
```batch
REM execute_all_with_tracking.bat
@echo off
setlocal enabledelayedexpansion

for %%f in (local_mcp\agents\*_OPTIMIZED.py) do (
    echo Running %%f...
    python "%%f"
    echo Exit Code: !ERRORLEVEL!
)
```

**Linux/Mac:**
```bash
# execute_all_with_tracking.sh
#!/bin/bash
for agent in local_mcp/agents/*_OPTIMIZED.py; do
    echo "Running $agent..."
    python "$agent"
    echo "Exit Code: $?"
done
```

### CI/CD Integration

**GitHub Actions Example:**
```yaml
name: V2.2 Pipeline Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      
      - name: Install dependencies
        run: |
          pip install pyyaml psutil
      
      - name: Run quick test
        run: |
          python orchestrator.py --run quick_test --config orchestrator_config.yaml
      
      - name: Run integration tests
        run: |
          python orchestrator.py --run test_pipeline --config orchestrator_config.yaml
      
      - name: Upload results
        uses: actions/upload-artifact@v2
        with:
          name: pipeline-results
          path: pipeline_results/
```

### Custom Agent Development

**Template:**
```python
#!/usr/bin/env python3
"""
My Custom Agent
Purpose: <describe purpose>
"""
import sys
import json

def main():
    try:
        # Agent logic here
        result = {
            "status": "success",
            "data": "processing complete"
        }
        
        print(json.dumps(result, indent=2))
        return 0
        
    except Exception as e:
        print(f"ERROR: {e}", file=sys.stderr)
        return 1

if __name__ == "__main__":
    sys.exit(main())
```

---

## ğŸ“š REFERENCE

### Command Reference

#### Orchestrator
```bash
python orchestrator.py [OPTIONS]

Options:
  --run PIPELINE          Run specified pipeline
  --config FILE           Config file (default: orchestrator_config.yaml)
  --debug                 Enable remote debugging
  --verbose               Verbose output
  --dry-run              Validate without executing
  --timeout SECONDS       Override default timeout
  --output-dir DIR        Results directory
  --list-agents          Show all agents
  --list-pipelines       Show all pipelines
  --health-check         System health check
  --validate-config      Validate configuration
  --help                 Show help message
```

#### MCP Controller
```bash
python mcp_controller.py [OPTIONS]

Options:
  --list-agents          List all agents
  --list-pipelines       List all pipelines
  --run PIPELINE         Execute pipeline
  --status               Show system status
  --help                 Show help
```

#### Component Tests
```bash
python keb.py --test                    # Test KEB
python gbogeb.py --test                 # Test GBOGEB
python execution_tracker.py --test      # Test tracker
python analyze_executions.py            # Analyze logs
```

### File Locations

```
Master_Input/
â”œâ”€â”€ orchestrator.py              # Main orchestrator
â”œâ”€â”€ orchestrator_config.yaml     # Configuration
â”œâ”€â”€ keb.py                       # Execution backbone
â”œâ”€â”€ gbogeb.py                    # Observability
â”œâ”€â”€ execution_tracker.py         # Tracking system
â”œâ”€â”€ analyze_executions.py        # Analysis tool
â”œâ”€â”€ mcp_controller.py            # MCP interface
â”‚
â”œâ”€â”€ local_mcp/agents/            # Agent directory
â”‚   â”œâ”€â”€ *_OPTIMIZED.py          # 6 stub agents
â”‚   â””â”€â”€ CANONICAL_*.py          # 6 canonical agents
â”‚
â”œâ”€â”€ pipeline_results/            # Execution results
â”œâ”€â”€ execution_tracking/          # Tracking data
â”‚   â”œâ”€â”€ audit/
â”‚   â”œâ”€â”€ executions/
â”‚   â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ phases/
â”‚
â”œâ”€â”€ setup_environment_v2.2.ps1   # Windows setup
â”œâ”€â”€ setup_environment_v2.2.sh    # Linux/Mac setup
â””â”€â”€ execute_all_with_tracking.*  # Batch scripts
```

### Exit Codes

| Code | Meaning |
|------|---------|
| 0 | Success |
| 1 | General error |
| 2 | Configuration error |
| 3 | Agent not found |
| 4 | Timeout exceeded |
| 5 | Import error |
| 99 | Unknown error |

### Version Information

```
System Version: 2.2.0
Release Date: 2025-11-11
Python Required: 3.8+
Status: Production Ready âœ…

Agent Versions:
- OPTIMIZED Stubs: v2.1
- Canonical CRYO: v3.0
- Canonical Document Consumer: v6.1.0
- Canonical Recursive Framework: v6.0.0
- Other Canonicals: v2.0
```

---

## ğŸ“ SUPPORT & RESOURCES

### Documentation
- **Implementation Guide:** V2.2_IMPLEMENTATION_COMPLETE.md
- **Execution Plan:** V2.2_EXECUTION_PLAN.md
- **Test Results:** V2.2_COMPREHENSIVE_TEST_RESULTS.md
- **Quick Reference:** V2.2_SESSION_QUICK_REFERENCE.md
- **Changelog:** CHANGELOG_V2.2.md
- **This Guide:** V2.2_USER_GUIDE.md

### Quick Links
- Configuration: `orchestrator_config.yaml`
- Agent Directory: `local_mcp/agents/`
- Results: `pipeline_results/`
- Tracking: `execution_tracking/`

### Tips
1. Start with `quick_test` for validation
2. Use `--verbose` during development
3. Check `execution_tracking/` for audit trails
4. Run `analyze_executions.py` for insights
5. Enable `--debug` for troubleshooting

---

**Last Updated:** 2025-11-11  
**Document Version:** 1.0  
**System Version:** 2.2.0  
**Status:** Production Ready âœ…
